---
id: SVM
aliases: []
tags: []
---

**SVM(Support Vector Machine, 서포트 벡터 머신)** 은 기계 학습(Machine Learning)에서 가장 유명하고 강력한 **지도 학습 모델** 중 하나입니다. 주로 데이터를 두 개의 그룹으로 **분류(Classification)** 하는 데 사용되지만, 수치 예측(회귀)에도 사용할 수 있습니다.

한 마디로 정의하자면, **"데이터들을 나누는 가장 안전하고 넓은 경계선(도로)을 찾는 알고리즘"** 입니다.

-----

### 1\. 핵심 아이디어: 가장 넓은 도로 만들기

두 종류의 데이터(예: 빨간 공과 파란 공)가 바닥에 흩어져 있다고 상상해 보세요. 이 둘을 구분하기 위해 막대기 하나를 놓으려고 합니다.

  * 막대기를 놓을 수 있는 방법은 무수히 많습니다.
  * 하지만 SVM은 **두 그룹 사이의 간격(도로의 폭)이 가장 넓어지는 위치**에 막대기를 놓습니다.
  * 이렇게 해야 나중에 새로운 데이터가 들어왔을 때도 더 정확하게 구분할 수 있기 때문입니다.

### 2\. 주요 용어 정리

SVM을 이해하기 위해 꼭 알아야 할 세 가지 개념이 있습니다.

  * **결정 경계 (Hyperplane):** 데이터를 나누는 기준이 되는 선(또는 면)입니다. 2차원에서는 '선'이지만, 3차원 이상에서는 '면(초평면)'이 됩니다.
  * **서포트 벡터 (Support Vectors):** 결정 경계와 가장 가까이 있는 데이터 포인트들입니다. 이 점들이 경계선의 위치를 결정하는 "지지대(Support)" 역할을 합니다. (나머지 멀리 있는 점들은 경계선 모양에 영향을 주지 않습니다.)
  * **마진 (Margin):** 결정 경계와 서포트 벡터 사이의 거리입니다. SVM의 목표는 이 **마진을 최대화**하는 것입니다.

### 3\. 직선으로 나눌 수 없다면? (커널 트릭)

데이터가 단순히 직선 하나로 나누어지지 않고 복잡하게 섞여 있는 경우(비선형 데이터)는 어떻게 할까요?

이때 SVM은 **'커널 트릭(Kernel Trick)'**이라는 수학적 기법을 사용합니다.

  * 2차원 평면에 있는 데이터를 3차원 공간으로 던져 올린다고 상상해 보세요.
  * 평면에서는 섞여 있던 데이터가 입체 공간에서는 높낮이 차이로 인해 평평한 판 하나로 깔끔하게 나뉠 수 있게 됩니다.

-----

### 4\. 장점과 단점 요약

| 특징 | 설명 |
| :--- | :--- |
| **장점** | • **정확성:** 데이터의 특성이 많아도(고차원) 잘 작동합니다.<br>• **일반화:** 마진을 최대화하므로, 새로운 데이터에 대한 오류가 적습니다.<br>• **적은 데이터:** 데이터 양이 적어도 비교적 좋은 성능을 냅니다. |
| **단점** | • **속도:** 데이터 양이 아주 많으면 학습 속도가 매우 느려집니다.<br>• **노이즈:** 데이터에 노이즈(이상치)가 많거나 서로 겹쳐 있으면 성능이 떨어집니다.<br>• **해석:** 결과가 왜 그렇게 나왔는지 직관적으로 이해하기 어렵습니다(Black box). |

-----

### 요약

SVM은 단순히 정답을 맞히는 것뿐만 아니라, **"데이터 간의 거리를 가장 넓게 확보하여 안정적으로 정답을 맞히는 기준선"**을 찾아주는 알고리즘입니다.

**혹시 파이썬(Scikit-learn)을 사용한 간단한 SVM 예제 코드를 보여드릴까요?**
