# Random Variables (확률변수)

## Definition and Concept

확률변수는 무작위 현상의 결과에 따라 값이 달라지는 변수입니다. 가장 간단한 의미로, 특정 분포를 따르는 변수입니다.

우리가 살고 있는 예측 불가능한 세계에서는 동전 던지기부터 날씨 패턴까지 수많은 무작위 이벤트를 매일 접합니다. 실제 세계는 상당한 무작위성을 포함하고 있지만, 수학은 제한된 설정이나 공간 내에서 이러한 무작위성을 줄이려고 시도합니다. 그러나 진정한 확률변수는 정의상 완전한 확실성으로 예측하는 것이 불가능합니다.

확률변수를 예측과 분석에 유용하게 만들기 위해, 특히 머신러닝과 딥러닝에서는 특정 확률 분포를 따르는 이벤트의 집합으로 정의합니다.

## Why Use Probability Distributions?

무작위성에만 집중하면 예측이 불가능해집니다. 따라서 데이터가 특정 알려진 확률 분포로부터 생성되었다는 가정을 합니다. 이는 다음과 같은 일을 가능하게 하는 수학적 구조를 제공합니다:

1. 예측하기
2. 불확실성 정량화하기
3. 확률론적 프레임워크에 기반한 모델 구축하기
4. 가설 검정하기

## Key Probability Distributions

### 1. Bernoulli Distribution

베르누이 분포는 가장 단순한 이산 확률 분포로, 단일 이진 결과를 모델링합니다:

- 두 가지 가능한 결과(성공/실패)가 있는 단일 시행을 나타냅니다
- 매개변수: p (성공 확률)
- 예시: 단일 동전 던지기 (앞면/뒷면)

수학적 표현: $X \sim \text{Bernoulli}(p)$ 일 때
- $P(X=1) = p$
- $P(X=0) = 1-p$
- $E[X] = p$
- $\text{Var}(X) = p(1-p)$

### 2. Binomial Distribution

이항 분포는 여러 개의 독립적인 베르누이 시행을 수행한 결과입니다:

- n개의 독립적인 시행에서 성공의 수를 나타냅니다
- 매개변수: n (시행 횟수)와 p (성공 확률)
- 예시: 10번의 동전 던지기에서 앞면이 나오는 횟수

수학적 표현: $X \sim \text{Binomial}(n,p)$ 일 때
- $P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$
- $E[X] = np$
- $\text{Var}(X) = np(1-p)$

### 3. Normal (Gaussian) Distribution

가우스가 개발한 정규 분포는 가장 중요한 연속 확률 분포입니다:

- 종 모양이며, 평균을 중심으로 대칭적입니다
- 매개변수: μ (평균)와 σ² (분산)
- 예시: 사람들의 키, 측정 오차, 많은 자연 현상

수학적 표현: $X \sim N(\mu,\sigma^2)$ 일 때
- 확률 밀도 함수: $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
- $E[X] = \mu$
- $\text{Var}(X) = \sigma^2$

정규 분포의 중요성은 중심 극한 정리에서 비롯됩니다. 중심 극한 정리는 원래 분포에 관계없이 많은 독립적인 확률 변수의 합이 정규 분포에 근접한다고 말합니다.

## Applications in Machine Learning

머신러닝에서 확률 분포는 많은 모델에 대한 기본적인 가정으로 작용합니다:

### Linear Regression

선형 회귀에서 핵심 가정은 목표 변수(y)가 예측 값 주변에서 정규 분포를 따른다는 것입니다. 구체적으로:

- $y = X\beta + \varepsilon$, 여기서 $\varepsilon \sim N(0,\sigma^2)$
- 오차는 평균이 0인 정규 분포를 따른다고 가정됩니다

이 가정은 신뢰 구간, 가설 검정 및 기타 추론 도구의 도출을 가능하게 합니다.

### Maximum Likelihood Estimation

많은 ML 알고리즘은 데이터의 확률 분포에 대한 가정에 의존하는 최대 우도 추정을 사용합니다:

- 분류 작업은 종종 베르누이 또는 다항 분포를 가정합니다
- 회귀 작업은 종종 정규 분포를 가정합니다
- 카운트 데이터는 포아송 분포를 가정할 수 있습니다

### Bayesian Methods

베이지안 접근법은 매개변수를 사전 분포가 있는 확률 변수로 명시적으로 모델링하며, 이는 관측된 데이터를 기반으로 사후 분포로 업데이트됩니다.

매개변수 $\theta$와 데이터 $D$에 대해, 사후 분포는 다음과 같습니다:

$P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}$

여기서:
- $P(\theta|D)$는 데이터가 주어졌을 때 매개변수의 사후 확률입니다
- $P(D|\theta)$는 매개변수가 주어졌을 때 데이터의 가능도입니다
- $P(\theta)$는 매개변수의 사전 확률입니다
- $P(D)$는 데이터의 한계 가능도입니다

## Why Understanding Distributions Matters

Python에서 확률 분포를 구현하는 것은 간단할 수 있지만(종종 NumPy나 SciPy와 같은 라이브러리를 사용하여 한 줄로 가능), 더 깊은 이해는 다음과 같은 이유로 중요합니다:

1. 모델 결과를 올바르게 해석하기
2. 모델 가정이 위반되었을 때 진단하기
3. 특정 데이터 유형에 적합한 모델 선택하기
4. 모델 가정에 더 잘 맞도록 특성 엔지니어링하기
5. 예측의 불확실성 정량화하기

## Conclusion

확률변수는 통계적 학습과 머신러닝의 근간을 형성합니다. 특정 현상이 특정 확률 분포를 따른다고 가정함으로써, 우리는 세상의 본질적인 무작위성에도 불구하고 예측을 할 수 있는 수학적 프레임워크를 만듭니다. 이러한 분포와 그 특성을 이해하면 더 효과적인 모델을 구축하고 그 결과를 더 잘 해석할 수 있습니다.
