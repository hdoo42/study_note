# History

## Summary

평균(Average)과 기댓값(Expectation)은 통계학의 핵심 개념으로, 데이터의 중심 경향을 나타내는 중요한 척도입니다. 이 문서에서는 평균과 기댓값의 개념이 통계학의 역사 속에서 어떻게 발전해왔는지 살펴보고, 이러한 개념들이 현대 통계학과 데이터 과학에 미치는 영향을 탐구합니다.

## 1. 고대의 평균 개념

평균의 개념은 매우 오래된 역사를 가지고 있습니다. 고대 바빌로니아와 이집트에서는 천문학적 관측과 토지 측량에서 이미 기본적인 산술 평균을 사용했습니다. 그리스 수학자 유클리드와 피타고라스 또한 산술, 기하, 조화 평균의 개념을 연구했습니다.

### 1.1 산술 평균의 초기 사용

기원전 3세기경, 그리스의 천문학자 아리스타르쿠스(Aristarchus)는 태양과 달의 거리를 측정하기 위해 여러 관측치의 산술 평균을 사용했습니다. 이는 관측 오차를 줄이기 위한 초기의 시도였습니다.

## 2. 중세와 르네상스 시대의 발전

중세 시대에는 통계적 개념의 발전이 제한적이었지만, 르네상스 시대에 이르러 상업과 항해술의 발달로 인해 확률 이론과 평균 개념이 더욱 중요해졌습니다.

### 2.1 이탈리아 상인들과 기대 이익

14-15세기 이탈리아 상인들은 무역 위험을 평가하기 위해 기대 이익(expected profit)의 개념을 사용하기 시작했습니다. 이는 현대적 기댓값 개념의 초기 형태였습니다.

## 3. 확률론의 탄생과 기댓값의 공식화

### 3.1 파스칼과 페르마의 서신 교환 (1654)

현대적 의미의 기댓값 개념은 17세기 프랑스 수학자 블레즈 파스칼(Blaise Pascal)과 피에르 드 페르마(Pierre de Fermat)의 유명한 서신 교환에서 처음 공식화되었습니다. 이들은 도박 문제를 해결하기 위해 확률과 평균적 결과(기댓값)의 개념을 수학적으로 정립했습니다.

### 3.2 크리스티안 하위헌스의 공헌 (1657)

네덜란드 수학자 크리스티안 하위헌스(Christiaan Huygens)는 1657년 출판한 "De Ratiociniis in Ludo Aleae"(확률 계산에 관하여)에서 기댓값(expectation)을 명시적으로 정의하고 공식화했습니다. 하위헌스는 기댓값을 "공정한 게임에서의 공정한 베팅 금액"으로 해석했습니다.

## 4. 18세기: 오일러와 베르누이 가문의 공헌

### 4.1 제이콥 베르누이와 대수의 법칙 (1713)

스위스 수학자 제이콥 베르누이(Jacob Bernoulli)는 그의 저서 "Ars Conjectandi"(추측의 기술)에서 대수의 법칙(Law of Large Numbers)을 증명했습니다. 이 법칙은 시행 횟수가 증가할수록 관측된 평균이 이론적 기댓값에 가까워진다는 것을 보여줍니다.

### 4.2 아브라함 드 무아브르와 정규 분포 (1733)

프랑스 수학자 아브라함 드 무아브르(Abraham de Moivre)는 이항 분포의 근사로서 정규 분포를 발견했고, 평균과 기댓값을 분포의 중심 매개변수로 사용했습니다.

### 4.3 라플라스와 중심 극한 정리 (1812)

피에르-시몽 라플라스(Pierre-Simon Laplace)는 중심 극한 정리(Central Limit Theorem)를 정립함으로써 표본 평균의 분포가 정규 분포에 수렴함을 증명했습니다. 이는 통계적 추론의 기초가 되었습니다.

## 5. 19세기: 통계학의 학문적 정립

### 5.1 아돌프 케틀레와 사회 통계학 (1830s)

벨기에 통계학자 아돌프 케틀레(Adolphe Quetelet)는 사회 현상을 연구하기 위해 평균의 개념을 적용했습니다. 그는 "평균적 인간(l'homme moyen)"이라는 개념을 도입하여 사회 통계학의 기초를 마련했습니다.

### 5.2 프란시스 골턴과 회귀 (1886)

영국의 과학자 프란시스 골턴(Francis Galton)은 평균으로의 회귀(regression toward the mean) 현상을 발견했습니다. 이는 극단적인 관측값이 평균값으로 회귀하는 경향을 설명하는 것으로, 현대 회귀 분석의 기초가 되었습니다.

### 5.3 칼 피어슨과 상관 계수 (1895)

칼 피어슨(Karl Pearson)은 상관 계수를 개발하고, 평균과의 편차를 기반으로 하는 여러 통계적 방법론을 정립했습니다.

## 6. 20세기: 현대 통계학의 발전

### 6.1 로널드 피셔와 실험 설계 (1920s)

로널드 피셔(Ronald Fisher)는 실험 설계와 분산 분석(ANOVA)을 개발하여 평균 간의 차이를 검정하는 방법론을 제시했습니다. 이는 현대 실험 통계학의 기초가 되었습니다.

### 6.2 확률론의 공리화와 콜모고로프 (1933)

안드레이 콜모고로프(Andrey Kolmogorov)는 확률론을 공리화하여 현대적인 수학적 기반을 마련했습니다. 그의 체계에서 기댓값은 르베그 적분으로 정의되어 더 넓은 범위의 확률 변수에 적용될 수 있게 되었습니다.

### 6.3 튜키와 탐색적 데이터 분석 (1970s)

존 튜키(John Tukey)는 평균만으로는 데이터의 특성을 충분히 파악할 수 없다고 주장하며, 중앙값, 사분위수 등 다양한 집중 경향 측도를 사용하는 탐색적 데이터 분석(EDA)을 발전시켰습니다.

## 7. 평균과 기댓값의 수학적 정의

### 7.1 이산 확률 변수의 기댓값

이산 확률 변수 X의 기댓값은 다음과 같이 정의됩니다:

E[X] = Σ x·P(X=x)

여기서 합은 X의 모든 가능한 값에 대해 계산됩니다.

### 7.2 연속 확률 변수의 기댓값

연속 확률 변수 X의 기댓값은 다음과 같이 정의됩니다:

E[X] = ∫ x·f(x) dx

여기서 f(x)는 X의 확률 밀도 함수입니다.

### 7.3 표본 평균과 모집단 평균

표본 평균(sample mean)은 관측된 데이터의 산술 평균으로 계산됩니다:

x̄ = (1/n) Σ xᵢ

모집단 평균(population mean)은 이론적인 기댓값인 μ = E[X]입니다. 대수의 법칙에 의해, 표본 크기가 충분히 크면 표본 평균은 모집단 평균에 근사합니다.

## 8. 평균과 기댓값의 현대적 응용

### 8.1 금융과 위험 관리

현대 금융 이론에서는 기댓값을 사용하여 투자의 기대 수익률과 위험을 평가합니다. 마코위츠의 현대 포트폴리오 이론(1952)은 기대 수익과 분산을 기반으로 최적 포트폴리오를 구성하는 방법을 제시했습니다.

### 8.2 머신러닝과 인공지능

머신러닝에서는 평균 제곱 오차(Mean Squared Error, MSE)와 같은 평균 기반 손실 함수를 최소화하는 방식으로 모델을 학습시킵니다. 또한 기댓값은 강화학습에서 보상의 기대값을 최대화하는 정책을 찾는 데 중요한 역할을 합니다.

### 8.3 빅데이터와 베이지안 통계

빅데이터 시대에 들어서면서, 베이지안 통계학에서는 기댓값을 사후 분포(posterior distribution)의 요약 통계량으로 사용합니다. 이는 불확실성 하에서의 의사결정을 지원합니다.

## 9. 결론

평균과 기댓값의 개념은 고대의 단순한 산술 계산에서 시작하여, 근대 확률론의 탄생과 함께 수학적으로 정립되었으며, 현대에 이르러 다양한 학문과 실용 분야에서 필수적인 도구가 되었습니다. 이러한 개념의 역사적 발전은 통계학의 진화를 보여주는 중요한 사례이며, 앞으로도 데이터 과학과 인공지능의 발전과 함께 계속해서 중요한 역할을 할 것입니다.

## 참고문헌

1. Stigler, S. M. (1986). The History of Statistics: The Measurement of Uncertainty before 1900. Harvard University Press.
2. Hald, A. (2003). A History of Probability and Statistics and Their Applications before 1750. Wiley.
3. Porter, T. M. (1986). The Rise of Statistical Thinking, 1820-1900. Princeton University Press.
4. David, H. A. (1995). First (?) Occurrence of Common Terms in Mathematical Statistics. The American Statistician, 49(2), 121-133.
5. Pearson, K. (1978). The History of Statistics in the 17th and 18th Centuries. Macmillan.

## 10. 디지털 시대의 평균과 기댓값

### 10.1 빅데이터와 분산 컴퓨팅

빅데이터 시대에는 방대한 양의 데이터에서 평균과 기댓값을 효율적으로 계산하는 것이 중요한 과제가 되었습니다. MapReduce와 같은 분산 컴퓨팅 패러다임은 대규모 데이터셋에서 평균을 계산하는 과정을 병렬화하여 효율성을 높였습니다.

### 10.2 온라인 학습과 점진적 평균 계산

실시간 데이터 스트림을 다루는 온라인 학습 알고리즘에서는 모든 데이터를 저장하지 않고도 평균을 갱신할 수 있는 점진적 평균 계산 방법이 중요합니다. 이러한 방법은 IoT 장치와 같은 제한된 리소스 환경에서 특히 유용합니다.

### 10.3 이상치 탐지와 로버스트 통계

현실 데이터에는 종종 이상치가 포함되어 있어 산술 평균이 왜곡될 수 있습니다. 이러한 문제를 해결하기 위해 중앙값, 절사 평균(trimmed mean), M-추정량과 같은 로버스트 통계 방법이 발전했습니다. 이러한 방법들은 사이버 보안, 부정 탐지, 센서 네트워크 등 다양한 분야에서 활용됩니다.

## 11. 인공지능과 평균 개념의 확장

### 11.1 딥러닝에서의 기울기 기반 최적화

딥러닝의 확률적 경사 하강법(SGD)은 미니배치의 손실 함수 기울기 평균을 사용하여 모델 파라미터를 갱신합니다. Adam, RMSProp과 같은 고급 최적화 알고리즘은 기울기의 지수 이동 평균(exponential moving average)을 사용하여 학습 과정을 안정화합니다.

### 11.2 앙상블 학습과 모델 평균화

랜덤 포레스트, 그래디언트 부스팅과 같은 앙상블 학습 방법은 여러 모델의 예측을 평균화하여 성능을 향상시킵니다. 이는 개별 모델의 분산을 줄이고 일반화 성능을 개선하는 효과가 있습니다. 최근의 연구에서는 베이지안 모델 평균화를 통해 모델 불확실성을 더 잘 포착하려는 시도가 이루어지고 있습니다.

### 11.3 강화학습에서의 템포럴 차이 학습

강화학습에서 사용되는 TD(Temporal Difference) 학습은 현재 추정치와 다음 상태에서의 추정치 간의 차이를 이용하여 가치 함수를 갱신합니다. 이는 몬테카를로 방법보다 효율적으로 기댓값을 추정할 수 있게 합니다. DQN, A3C, PPO와 같은 최신 강화학습 알고리즘은 이러한 기댓값 추정을 심층 신경망과 결합합니다.

## 12. 데이터 과학에서의 평균과 기댓값의 미래

### 12.1 인과 추론과 반사실적 기댓값

최근 인과 추론 분야에서는 반사실적 기댓값(counterfactual expectation)이 중요한 개념으로 부상하고 있습니다. 이는 "만약 다른 처치를 했다면 어떤 결과가 발생했을까?"라는 질문에 답하는 데 필요한 개념으로, 의학, 경제학, 정책 평가 등의 분야에서 중요한 역할을 합니다.

### 12.2 설명 가능한 AI와 특성 중요도

설명 가능한 AI 분야에서는 SHAP(SHapley Additive exPlanations)과 같은 방법이 각 특성의 중요도를 평가하기 위해 조건부 기댓값의 개념을 활용합니다. 이는 복잡한 AI 모델의 결정 과정을 이해하고 신뢰성을 높이는 데 기여합니다.

### 12.3 분산 학습과 연합 학습

프라이버시 보호가 중요해지면서, 데이터를 중앙에 집중시키지 않고 분산된 장치에서 모델을 학습시키는 연합 학습(Federated Learning)이 주목받고 있습니다. 이 방법은 각 장치에서 학습된 모델 파라미터의 평균을 계산하여 전체 모델을 갱신합니다. 이는 평균의 개념을 분산 환경에 확장한 것으로 볼 수 있습니다.

## 13. 결론: 평균과 기댓값의 보편성과 진화

평균과 기댓값의 개념은 고대의 단순한 산술 계산에서 시작하여 르네상스 시대의 확률 이론, 19세기의 통계학적 정립, 20세기의 공리적 접근을 거쳐 현대의 복잡한 데이터 과학과 인공지능 분야까지 진화해왔습니다. 이 개념들은 단순함에도 불구하고 자연과학, 사회과학, 공학 등 다양한 분야에서 핵심적인 역할을 하며, 불확실성을 다루는 보편적인 도구로 자리 잡았습니다.

21세기에는 빅데이터, 딥러닝, 강화학습 등의 발전과 함께 평균과 기댓값의 개념이 더욱 확장되고 정교화되고 있습니다. 로버스트 통계, 베이지안 방법론, 인과 추론 등의 발전은 이러한 개념들이 더 복잡한 실세계 문제에 적용될 수 있게 합니다. 앞으로도 평균과 기댓값은 데이터 기반 의사결정과 과학적 탐구의 중심에 있을 것이며, 새로운 이론적 발전과 실용적 응용을 통해 계속해서 진화할 것입니다.

## 추가 참고문헌

6. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
7. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning. Springer.
8. Pearl, J. (2009). Causality: Models, Reasoning, and Inference. Cambridge University Press.
9. Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction. MIT Press.
10. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
