**데이터 누수(Data Leakage)** 는 머신러닝 모델을 학습시킬 때, **"나중에 맞춰야 할 정답(테스트 데이터)의 정보가 학습 과정에 미리 새어 들어가는 현상"**을 말합니다.

쉽게 비유하자면 **"수능 시험(테스트)을 보는데, 시험 문제와 정답을 미리 보고(학습) 시험장에 들어가는 것"** 과 같습니다.

---

### 1. 왜 이게 문제인가요? (치명적인 이유)

- **거짓된 고성능:** 모델이 문제를 '이해'해서 푸는 게 아니라, 정답을 '미리 봐서' 맞추기 때문에 **테스트 점수(정확도)가 비정상적으로 높게 나옵니다.**
    
- **실전 실패:** 막상 이 모델을 실제 현업(Real World)에 투입하면, 처음 보는 데이터에 대해서는 엉망인 결과를 내놓습니다. (과적합, Overfitting)
    

![data leakage in machine learning diagram 이미지](https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcQt9NeRj2bIh-ov7LulFYK8ewAv3Yfm7Y5dYBxFStFFUZof-T_O_qCM_InV7bd1fQaXK2ILonTEW-4yDDYcX3Q3EkzEa2wa1olBWAhNm9xeqsGrB7U)

### 2. ADASYN/SMOTE에서 누수가 발생하는 원리

아까 제가 **"반드시 데이터를 먼저 나누고(Split), 학습 데이터(Train)에만 ADASYN을 적용하라"** 고 했던 이유가 바로 이것입니다.

**잘못된 순서 (누수 발생):**

1. 전체 데이터(`X`, `y`)에 ADASYN을 적용해 데이터를 뻥튀기합니다.
    
2. 이 데이터를 `Train`과 `Test`로 나눕니다.
    

> 무슨 일이 벌어지나요?
> 
> ADASYN은 데이터를 합성할 때 주변 데이터(이웃)를 참조합니다. 전체 데이터에 적용하면, 나중에 Test 셋으로 가야 할 데이터까지 참조해서 합성 데이터를 만듭니다.
> 
> 결과적으로, Train 셋 안에 Test 데이터의 패턴(정보)이 이미 섞여 들어갑니다.

**올바른 순서 (누수 방지):**

1. 전체 데이터를 `Train`과 `Test`로 먼저 나눕니다.
    
2. `Train` 데이터만 가지고 ADASYN을 적용합니다. (`Test`는 건드리지 않음)
    
3. 모델을 학습시킵니다.
    

### 3. 또 다른 흔한 누수 사례들

오버샘플링 외에도 흔히 실수하는 누수 사례가 있습니다.

- **스케일링(Scaling) 실수:**
    
    - 데이터를 나누기 전에 전체 데이터로 `MinMaxScaler`나 `StandardScaler`를 적용하는 경우.
        
    - (전체 평균과 분산에 테스트 데이터의 정보가 포함됨)
        
- **미래 정보 포함:**
    
    - 예측하려는 시점에는 알 수 없는 '미래의 값'을 피처(Feature)로 넣는 경우.
        
    - (예: '내일 비가 올지' 예측하는데, 피처에 '내일 우산 판매량'이 들어감)
        

### 4. 해결책

가장 확실한 방법은 **Pipeline**을 사용하는 것입니다.

Python

```
# 파이프라인을 쓰면 실수할 걱정이 없습니다.
pipeline = Pipeline([
    ('oversampler', ADASYN()),       # 1. 오버샘플링
    ('scaler', StandardScaler()),    # 2. 스케일링
    ('model', DecisionTreeClassifier()) # 3. 모델 학습
])

# fit을 할 때 알아서 Train 데이터에만 전처리를 적용합니다.
pipeline.fit(X_train, y_train)
```

요약하자면:

모델을 평가할 때(Test) 사용할 데이터는, 학습 과정(전처리, 튜닝, 학습)에서 절대로 눈길조차 줘서는 안 됩니다.