## 🤖 과적합 (Overfitting)

**과적합(Overfitting)** 은 **기계 학습 모델**이 **훈련 데이터(Training Data)** 를 지나치게 잘 학습하여, 오히려 **새로운, 이전에 본 적 없는 데이터(테스트/실제 데이터)** 에 대한 성능(정확도)이 떨어지는 현상을 말합니다.

쉽게 말해, 모델이 훈련 데이터에 있는 **잡음(noise)** 이나 **우연한 패턴**까지 암기해버려, 데이터의 **본질적인 일반적인 패턴**을 놓치게 되는 것입니다.

---

### 🔍 과적합의 특징

- **훈련 성능 (Training Performance):** 매우 **높습니다**. 모델이 훈련 데이터를 거의 완벽하게 분류하거나 예측합니다.
    
- **일반화 성능 (Generalization Performance) / 테스트 성능:** 매우 **낮습니다**. 훈련 데이터와는 미묘하게 다른 새로운 데이터에 대해서는 예측을 잘 못 합니다.
    

---

### 💡 과적합의 발생 원인

1. **모델의 복잡도 (Model Complexity):**
    
    - 모델이 지나치게 **복잡**하거나 (예: 너무 많은 레이어, 너무 많은 뉴런을 가진 신경망, 고차 다항식), 데이터의 양에 비해 **모델의 파라미터 수가 너무 많을 때** 발생하기 쉽습니다.
        
2. **훈련 데이터의 부족:**
    
    - 모델이 학습할 데이터가 **너무 적을 경우**, 해당 데이터에 특화된 패턴을 강제로 학습하게 됩니다.
        
3. **훈련의 과도함 (Too much training):**
    
    - 모델을 **필요 이상으로 오랫동안** 훈련할 경우, 초기에는 일반적인 패턴을 학습하다가 나중에는 훈련 데이터의 잡음까지 학습하게 됩니다.
        

---

### 🛡️ 과적합 방지/해결 방법

과적합을 방지하고 모델의 **일반화 성능**을 높이는 방법은 다음과 같습니다.

- **데이터 확보:** 가장 확실한 방법은 더 **많은** 훈련 데이터를 확보하는 것입니다.
    
- **정규화 (Regularization):**
    
    - 모델의 **파라미터(가중치) 값에 제약**을 두어 모델이 극단적인 값이나 복잡한 패턴을 학습하는 것을 방지합니다. (예: L1/L2 정규화, 드롭아웃(Dropout))
        
- **조기 종료 (Early Stopping):**
    
    - 훈련 데이터의 성능(손실)은 계속 좋아지더라도, **검증 데이터(Validation Data)** 의 성능이 더 이상 개선되지 않고 오히려 나빠지기 시작하는 지점에서 훈련을 멈춥니다.
        
- **데이터 증강 (Data Augmentation):**
    
    - 기존 데이터를 변형하여(예: 이미지 회전, 자르기, 색상 변경) 데이터의 양을 인위적으로 늘립니다.
        
- **모델 단순화:**
    
    - 모델의 복잡도를 줄입니다(예: 신경망의 레이어 또는 노드 수 줄이기).
        

과적합과 반대되는 개념으로는 모델이 데이터의 패턴을 제대로 파악하지 못하는 현상인 **과소적합(Underfitting)** 이 있습니다.

---

과적합과 과소적합에 대한 개념을 비교하는 표를 만들어서 설명해 드릴까요?