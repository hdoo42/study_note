데이터 불균형(Class Imbalance)이 99:1로 극심한 상황에서의 모델 성능 평가와 언더샘플링의 효과에 대해 명확하게 분석해 드리겠습니다.

---

### 1. 이 모델(M)의 정확도 (Accuracy)

**결론부터 말씀드리면, 정확도는 99%가 나올 가능성이 매우 높지만, 이는 '무의미한 숫자'일 확률이 큽니다.**

- 정확도의 역설 (Accuracy Paradox):
    
    데이터의 99%가 Class A입니다. 만약 모델이 아무런 학습을 하지 않고 "무조건 A라고 찍는" 단순한 전략을 취하더라도 정확도는 **99%** 가 나옵니다.
    
- 실제 문제점:
    
    머신러닝의 목적이 보통 희귀한 Class B(예: 암 환자, 불량품, 금융 사기 등)를 찾아내는 것이라면, 99%의 정확도를 가진 이 모델의 **Class B 탐지 능력(Recall)은 0%** 가 될 수 있습니다. 즉, 수치상으로는 훌륭해 보이지만 실제로는 전혀 쓸모없는 모델이 됩니다.
    

> **핵심 요약:** 불균형 데이터에서 단순 '정확도'는 모델의 성능을 나타내는 지표로 신뢰할 수 없습니다.

---

### 2. 언더샘플링 (Undersampling)을 적용하는 경우

언더샘플링은 다수 클래스인 A의 데이터를 B의 개수에 맞춰 줄여서(예: A 100개, B 100개) 1:1 비율로 학습시키는 방법입니다.

#### **예상되는 변화**

1. **정확도(Accuracy) 하락 가능성:**
    
    - 전체 데이터의 99%를 차지하는 A에 대한 학습 데이터가 대거 삭제되었으므로, A를 맞히는 능력이 떨어질 수 있습니다. 따라서 전체 정확도는 99%보다 낮아질 수 있습니다.
        
2. **재현율(Recall) 상승:**
    
    - 모델이 학습 과정에서 B를 A만큼 중요하게 여기게 됩니다. 그 결과, **Class B를 찾아내는 능력은 비약적으로 상승**합니다.
        
3. **결정 경계(Decision Boundary) 이동:**
    
    - 기존 모델이 A쪽으로 치우쳐져 B를 무시했다면, 언더샘플링 후에는 경계가 중앙으로 이동하여 B를 더 적극적으로 예측하게 됩니다.
        

#### **장점과 단점 (Trade-off)**

- **장점:** Class B(소수 클래스)를 감지할 확률이 높아집니다. 계산 비용이 줄어듭니다.
    
- **단점:** Class A(다수 클래스)의 정보가 대량으로 손실됩니다. 이로 인해 실제 운영 환경에서 정상 데이터(A)를 B로 잘못 예측하는 **오탐(False Positive)** 이 늘어날 수 있습니다.
    

---

### 3. 추천하는 분석 지표 및 전략

이러한 불균형 데이터 문제를 해결하고 올바르게 평가하기 위해서는 다음 지표들을 확인해야 합니다.

- **평가 지표 변경:**
    
    - **F1-Score:** 정밀도(Precision)와 재현율(Recall)의 조화 평균입니다.
        
    - **AUROC (Area Under ROC Curve):** 클래스 비율이 달라져도 비교적 강건한 성능 지표입니다.
        
    - **Confusion Matrix (오차 행렬):** 실제로 A와 B를 각각 몇 개나 맞췄는지 눈으로 확인해야 합니다.
        
- **대안 기법:**
    
    - **SMOTE (Oversampling):** 데이터를 버리는 대신, 소수 클래스(B)를 합성하여 늘리는 방법.
        
    - **Class Weight:** 학습 시 소수 클래스(B)를 틀렸을 때 더 큰 벌점(Loss)을 부과하는 방법.
        

---

이 데이터셋의 목적(예: A를 지키는 것이 중요한지, B를 찾아내는 것이 중요한지)에 따라 전략이 달라질 수 있습니다.
