데이터 차원의 저주(Curse of Dimensionality)는 **데이터 분석 및 머신러닝 문제에서 데이터의 차원(특성, feature)이 증가함에 따라 발생하는 여러 가지 문제점**을 총칭하는 용어입니다.

---

## 📉 주요 문제점

차원이 증가할 때 발생하는 핵심적인 문제는 다음과 같습니다.

- 데이터 희소성 (Sparsity of Data):
    
    차원이 증가하면, 데이터 공간의 부피가 기하급수적으로 커지게 됩니다. 이 거대한 공간에 비해 실제 데이터는 매우 적게 분포하게 되므로, 데이터가 서로 멀리 떨어져 '텅 빈' 상태처럼 보이게 됩니다. 이처럼 데이터가 희소해지면, 모델이 데이터를 일반화(generalize)하고 의미 있는 패턴을 학습하기가 매우 어려워집니다.
    
- 계산 비용 증가 (Increased Computational Cost):
    차원이 많아질수록 모델 학습 및 계산에 필요한 시간과 메모리가 급격히 증가합니다.
    
- 과적합 위험 증가 (Increased Risk of Overfitting):
    높은 차원에서 모델은 종종 노이즈나 무의미한 특성까지 학습하려고 시도하여, 학습 데이터에만 너무 잘 맞는([[과적합]]) 결과를 낳고 실제 새로운 데이터에서는 성능이 떨어지게 됩니다.
    
- 거리 개념 무의미화 (Deterioration of Distance Measures):
    고차원 공간에서는 모든 데이터 포인트 간의 거리가 거의 비슷해지는 현상이 발생하여, 유클리드 거리(Euclidean distance)와 같은 거리 기반 유사도 측정 방식이 신뢰성을 잃게 됩니다. 이는 K-최근접 이웃(K-NN)과 같은 알고리즘의 성능에 치명적입니다.
    

---

## 🛠️ 해결 방안

이러한 문제에 대응하기 위해 주로 **차원 축소(Dimensionality Reduction)** 기법이 사용됩니다.

- **특성 선택 (Feature Selection):** 가장 중요한 특성만 선택하고 나머지는 버립니다.
    
- **특성 추출 (Feature Extraction):** 기존 특성들을 조합하여 새로운 저차원 특성 공간을 만듭니다. (예: **주성분 분석, PCA**)
    

더 궁금한 점이나 PCA에 대해 자세히 알아보고 싶으신가요?