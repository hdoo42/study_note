
주어진 시나리오처럼 **정답(Positive, 1)**인 경우가 95%, **오답(Negative, 0)**인 경우가 5%로 극도로 불균형한 데이터셋에서, AI가 입력에 관계없이 무조건 **1**로만 예측하는 경우, 그 성능 지표는 다음과 같이 나타납니다.

---

### 1. 정확도 (Accuracy)

정확도는 전체 예측 중 올바르게 예측한 비율입니다.

$$Accuracy = \frac{\text{Correct Predictions}}{\text{Total Predictions}} = \frac{TP + TN}{TP + TN + FP + FN}$$

- **TP (True Positive):** 실제 1을 1로 예측 (95%)
    
- **TN (True Negative):** 실제 0을 0으로 예측 (0%)
    
- **FP (False Positive):** 실제 0을 1로 예측 (5%)
    
- **FN (False Negative):** 실제 1을 0으로 예측 (0%)
    

AI는 무조건 1로만 예측하기 때문에, 실제 정답인 95%의 경우를 모두 맞히고, 실제 오답인 5%의 경우를 모두 틀리게 됩니다.

$$Accuracy = \frac{95\% + 0\%}{95\% + 0\% + 5\% + 0\%} = \frac{95}{100} = \mathbf{0.95} \text{ 또는 } \mathbf{95\%}$$

이 AI의 **정확도는 95%** 로 매우 높게 나타나지만, 이는 AI가 데이터의 특징을 학습했기 때문이 아니라, 단순히 **다수 클래스(Majority Class)를 따라 찍었기 때문**입니다. 따라서 이 수치만으로는 AI의 **실질적인 예측 능력이나 유용성을 평가할 수 없습니다.**

---

### 2. 정밀도, 재현율, F1-Score (Precision, Recall, F1-Score)

불균형 데이터셋에서는 정확도 외에 **정밀도(Precision)**, **재현율(Recall)**, 그리고 이 둘의 조화 평균인 **F1-Score**를 함께 사용하여 AI의 성능을 종합적으로 평가해야 합니다.

#### 1) 정밀도 (Precision)

AI가 1로 예측한 것 중 실제 정답이 1인 비율 (모델이 1이라고 주장했을 때의 정확성).

$$Precision = \frac{TP}{TP + FP} = \frac{95\%}{95\% + 5\%} = \frac{95}{100} = \mathbf{0.95}$$

#### 2) 재현율 (Recall) 또는 민감도 (Sensitivity)

실제 정답 1인 것 중 AI가 1로 올바르게 예측한 비율 (실제 정답을 놓치지 않는 정도).

$$Recall = \frac{TP}{TP + FN} = \frac{95\%}{95\% + 0\%} = \frac{95}{95} = \mathbf{1.00}$$

#### 3) F1-Score

정밀도와 재현율의 조화 평균. 두 지표의 균형을 나타냅니다.

$$F1\text{-}Score = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} = 2 \cdot \frac{0.95 \cdot 1.00}{0.95 + 1.00} \approx \mathbf{0.974}$$

---

### 3. 결론 및 해석

|**지표**|**값**|**평가**|
|---|---|---|
|**정확도 (Accuracy)**|95%|**높지만 오해의 소지가 있음.** (다수 클래스 편향)|
|**정밀도 (Precision)**|0.95|높음.|
|**재현율 (Recall)**|1.00|매우 높음.|
|**F1-Score**|$\approx 0.974$|높음.|
|**실질적 유용성**|**제로**|소수 클래스(0)를 전혀 예측하지 못함.|

겉으로 보이는 **정확도와 다른 보조 지표들은 모두 매우 우수한 값**을 나타냅니다. 특히 재현율이 1.00으로 만점인 이유는 실제 1인 모든 케이스(95%)를 놓치지 않고 1로 예측했기 때문입니다.

하지만 이 모델은 유용하지 않습니다.

이는 모델이 **소수 클래스(Minority Class, 0인 경우)** 를 **단 한 번도 올바르게 예측하지 못했음(TN=0)** 을 의미합니다. 만약 0을 예측하는 것이 매우 중요한 문제(예: 희귀 질병 진단, 사기 탐지)라면, 이 AI는 95%의 높은 정확도에도 불구하고 완전히 무가치합니다. 이러한 현상을 **정확도의 함정(Accuracy Paradox)** 이라고 합니다.

**따라서 불균형 데이터셋에서는 정확도만으로 성능을 평가해서는 안 되며, 특히 소수 클래스에 대한 재현율(Recall for class 0)** 또는 **특이도(Specificity: 실제 0을 0으로 예측한 비율)** 같은 지표를 반드시 확인해야 합니다. (이 경우 특이도는 $\frac{TN}{TN+FP} = \frac{0}{0+5\%} = 0$ 입니다.)

---

이러한 경우, ROC 곡선(Receiver Operating Characteristic curve)이나 PR 곡선(Precision-Recall curve)과 같은 시각적 평가 방법이 더욱 유용합니다.
