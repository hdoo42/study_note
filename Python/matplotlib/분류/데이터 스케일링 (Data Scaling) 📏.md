**데이터 스케일링**은 머신러닝의 **데이터 전처리** 과정 중 하나로, 각 **피처(특성)** 들이 가지는 값의 **범위**나 **분포**를 일정한 기준으로 통일하는 작업입니다. 피처마다 값의 범위가 크게 다를 경우, 모델 학습 시 특정 범위가 큰 피처에 모델이 **편향**되거나, 최적화 과정에서 문제가 발생할 수 있습니다.

데이터 스케일링을 통해 모든 피처의 크기 기여도를 균일하게 조정하여 모델 학습의 안정성을 높이고 성능을 향상시키는 것이 주된 목적입니다.

---

## 최적화 과정의 안정성 및 수렴 속도 향상에 미치는 영향

데이터 스케일링은 주로 **경사 하강법(Gradient Descent)** 기반의 최적화 알고리즘을 사용하는 모델(예: 선형 회귀, 로지스틱 회귀, 신경망)과 **거리 기반** 알고리즘(예: K-NN, K-means, SVM)에 특히 중요하며, 다음과 같은 도움을 줍니다.

### 1. 최적화 과정의 안정성 및 수렴 속도 향상

- **비용 함수(Cost Function)의 모양 균일화:**
    
    - 스케일링을 하지 않으면 값의 범위가 큰 피처 축으로는 경사가 완만하고, 작은 피처 축으로는 경사가 가파른 **타원형** 또는 **찌그러진** 형태의 비용 함수 표면이 형성됩니다.
        
    - 이 경우, 경사 하강법을 적용하면 최적점(가장 낮은 지점)을 향해 한 번에 직선적으로 이동하지 못하고, **지그재그** 형태로 움직이면서 수렴하는 데 시간이 오래 걸리거나(느린 수렴), 심지어 발산할 위험이 있습니다.
        
    - 스케일링을 적용하면 모든 피처의 기여도가 비슷해져 비용 함수 표면이 **구형(Spherical)**에 가깝게 변합니다.
        
    - 이러면 경사 하강법이 보다 **직선적**이고 **효율적**으로 최적점으로 이동하여 **수렴 속도**가 빨라지고, 학습 과정의 **안정성**이 높아집니다.
        
- **조건수(Condition Number) 감소:**
    
    - 피처 간의 스케일 차이가 클 경우, 독립 변수의 공분산 행렬의 **조건수**가 커집니다. 조건수가 크면 행렬이 불안정하여 모델링의 해가 작은 오차에도 크게 변할 수 있습니다.
        
    - 스케일링을 통해 조건수를 감소시켜 모델 학습 시 **수치적 안정성**을 확보할 수 있습니다.
        

### 2. 거리 기반 알고리즘의 성능 향상

- K-최근접 이웃(K-NN)이나 K-평균 군집화(K-means), 서포트 벡터 머신(SVM)과 같은 **거리 기반** 알고리즘은 데이터 포인트 간의 **유클리드 거리** 등을 측정하여 유사성을 판단합니다.
    
- 스케일링을 하지 않으면, 값의 범위가 큰 피처(예: 재산)가 값의 범위가 작은 피처(예: 나이)보다 거리에 훨씬 더 큰 영향을 미치게 되어, 실제 데이터의 유사성을 왜곡하고 모델의 예측 성능을 저하시킬 수 있습니다.
    
- 스케일링을 적용하면 모든 피처가 유사한 중요도로 거리에 기여하게 되어, **공정한 비교**가 가능해지고 모델의 성능이 향상됩니다.
    

---

## 주요 스케일링 기법

### 1. 표준화 (Standardization) - StandardScaler

- **목표:** 데이터의 **평균($\mu$)을 0**으로, **표준편차($\sigma$)를 1**로 조정하여 **표준 정규 분포**를 따르도록 만듭니다 (Z-score).
    
- **수식:** 
$$x_{scaled} = \frac{x - \mu}{\sigma}$$
    
- **특징:** 상한과 하한의 범위가 없어 이상치(Outlier)의 영향을 덜 받지만, 이상치가 존재하면 평균과 표준편차가 영향을 받기에 여전히 민감할 수 있습니다.
    

### 2. 정규화 (Min-Max Scaling) - MinMaxScaler

- **목표:** 데이터의 최솟값($X_{min}$)을 0으로, 최댓값($X_{max}$)을 1로 조정하여 **[0, 1] 범위** 내에 데이터를 위치시킵니다.
    
- **수식:** $x_{scaled} = \frac{x - X_{min}}{X_{max} - X_{min}}$
    
- **특징:** 데이터의 범위가 명확하게 제한되지만, 이상치가 존재할 경우 최솟값/최댓값이 극단적으로 설정되어 데이터가 매우 좁은 범위로 압축될 수 있습니다(이상치에 민감).
    

### 3. 로버스트 스케일링 (Robust Scaling) - RobustScaler

- **목표:** **중앙값(median)**을 0으로, **사분위 범위(IQR, Interquartile Range)**를 1로 조정하여 스케일링합니다.
    
- **수식:** $x_{scaled} = \frac{x - \text{median}}{IQR}$
    
- **특징:** 평균과 표준편차 대신 중앙값과 IQR을 사용하기 때문에 **이상치(Outlier)의 영향**을 가장 적게 받습니다.